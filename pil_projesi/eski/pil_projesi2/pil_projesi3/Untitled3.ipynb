{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fc306d9-3855-417d-b1bf-d4dab90bf59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5, MSE: 11474.339551\n",
      "Fold 2/5, MSE: 16033.363415\n",
      "Fold 3/5, MSE: 16197.156291\n",
      "Fold 4/5, MSE: 18154.544127\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001EE9BF5FEC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold 5/5, MSE: 19076.448965\n",
      "\n",
      "Average CV MSE: 16187.170470\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[11474.339551248504,\n",
       " 16033.36341502776,\n",
       " 16197.15629110991,\n",
       " 18154.544127001824,\n",
       " 19076.44896510004]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import warnings\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Prepare dataset\n",
    "def create_sequences(data, window_size):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data[i:i+window_size])\n",
    "        y.append(data[i+window_size])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def walk_forward_cv(data, window_size=10, n_splits=5, epochs=50):\n",
    "    fold_size = (len(data) - window_size) // (n_splits + 1)\n",
    "    errors = []\n",
    "\n",
    "    for i in range(n_splits):\n",
    "        end_train = window_size + fold_size * (i + 1)\n",
    "        train_data = data[:end_train]\n",
    "        val_data = data[end_train:end_train + fold_size]\n",
    "\n",
    "        # Skip if not enough validation data\n",
    "        if len(val_data) < 1:\n",
    "            break\n",
    "\n",
    "        # Create sequences\n",
    "        X_train, y_train = create_sequences(train_data, window_size)\n",
    "        X_val, y_val = create_sequences(np.concatenate([train_data[-window_size:], val_data]), window_size)\n",
    "\n",
    "        # Reshape for LSTM\n",
    "        X_train = X_train[..., np.newaxis]\n",
    "        X_val = X_val[..., np.newaxis]\n",
    "\n",
    "        # Build model\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.LSTM(128, input_shape=(window_size, 1)),\n",
    "            tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "        model.compile(loss='mse', optimizer='adam')\n",
    "        model.fit(X_train, y_train, epochs=epochs, verbose=0)\n",
    "\n",
    "        # Evaluate\n",
    "        y_pred = model.predict(X_val, verbose=0).flatten()\n",
    "        error = mean_squared_error(y_val, y_pred)\n",
    "        errors.append(error)\n",
    "        print(f\"Fold {i+1}/{n_splits}, MSE: {error:.6f}\")\n",
    "\n",
    "    print(f\"\\nAverage CV MSE: {np.mean(errors):.6f}\")\n",
    "    return errors\n",
    "\n",
    "# Example usage:\n",
    "# voltage_data = np.array([...])  # Your 104 measurements\n",
    "# walk_forward_cv(voltage_data, window_size=10, n_splits=5, epochs=50)\n",
    "\n",
    "voltage_data = np.array([69.03, 71.27, 73.27, 76.2, 77.57, 79.14, 81.14, 83.14, 85.28, 86.79, 87.49, 89.91, 90.91, 92.8, 94.74, 96.94, 97.98,\n",
    "    99.28, 102.29, 103.23, 104.25, 105.25, 106.43, 107.14, 108, 109.03, 110.25, 112.82, 113.91, 115.07, 116.35, 117.98, 118.91,\n",
    "    119.19, 120.48, 121.28, 122.68, 123.16, 124.91, 125.81, 127.32, 128.62, 130.1, 131.02, 131.92, 132.76, 133.78, 134.7, 135.62,\n",
    "    136.38, 136.83, 137.24, 138.15, 139.05, 139.48, 139.83, 140.48, 141.48, 142.75, 143.22, 143.42, 144.62, 145.83, 147.03, 148.56,\n",
    "    149.1, 149.18, 150.55, 150.95, 151.35, 151.75, 152.15, 152.74, 153.34, 153.94, 154.53, 154.6, 155.02, 155.45, 156.78, 155.35, 156.1,\n",
    "    156.85, 159.14, 157.33, 158.38, 159.43, 160.48, 161.53, 162.58, 163.03, 163.49, 164.45, 163.76, 164.59, 165.43, 166.26, 166.04, 166.61,\n",
    "    167.17, 167.73, 168.3, 168.86, 169.9])\n",
    "\n",
    "walk_forward_cv(voltage_data, window_size=10, n_splits=5, epochs=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23109b41-729c-49e1-986a-d9046a8a0f8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:digi_twin] *",
   "language": "python",
   "name": "conda-env-digi_twin-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
